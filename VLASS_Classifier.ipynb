{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GalaxyClassifier_MRodriguez.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnbeasley1998/NINEworkshop/blob/master/VLASS_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKxwC3zNdOhG",
        "colab_type": "text"
      },
      "source": [
        "**Galaxy Classification**\n",
        "* We will start from scratch with 3 galaxy classifications. This data is not curated\n",
        "* 3 categories: diffuse, multiple, single\n",
        "* Images are monocromatic 960x960 pi\n",
        "* Series of 921 600 px\n",
        "\n",
        "Steps:\n",
        "1. Download data\n",
        "1. Load the data\n",
        "1. Run classifier\n",
        "1. Plot Function Loss\n",
        "\n",
        "Data is structured as:\n",
        "* ./images\n",
        "  * ./train\n",
        "    * ./single\n",
        "    * ./multiple\n",
        "    * ./diffused\n",
        "  * ./valid\n",
        "    * ./single\n",
        "    * ./multiple\n",
        "    * ./diffused"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-FFhdK7fgNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Methods to read data\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e94RzuoWQwYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transform and load datasets\n",
        "simple_transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "trainset = ImageFolder('/srv/data/my_shared_data_folder/v3/train/', simple_transform)\n",
        "validset = ImageFolder('/srv/data/my_shared_data_folder/v3/valid/', simple_transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVN2dN_5hh58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b8b0b957-2688-46af-eb3a-660a0a9fcd6a"
      },
      "source": [
        "print(trainset)\n",
        "type(trainset)\n",
        "\n",
        "print(validset)\n",
        "type(validset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 344\n",
            "    Root location: /content/drive/My Drive/NINE/Collab/PyTorch/PyTorch - ImageClassifier/GalaxyClassifier/images/v1/train\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 125\n",
            "    Root location: /content/drive/My Drive/NINE/Collab/PyTorch/PyTorch - ImageClassifier/GalaxyClassifier/images/v1/valid\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.folder.ImageFolder"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cjf8yP9XpfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbcf06ed-cdd6-4c3d-eb3e-080630c3897e"
      },
      "source": [
        "trainset.class_to_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'diffuse': 0, 'disturbed': 1, 'multiple': 2, 'single': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGI039aUXy92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4d7f063-6648-41c1-e9bb-66a8597c97dc"
      },
      "source": [
        "validset.class_to_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'diffuse': 0, 'disturbed': 1, 'multiple': 2, 'single': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_exs64JX6gF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0033b686-3214-4bf0-ca57-1f32126b1f3f"
      },
      "source": [
        "for key, value in trainset.class_to_idx.items():\n",
        "  print('Class is: ', key, ', Index is: ', value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class is:  diffuse , Index is:  0\n",
            "Class is:  disturbed , Index is:  1\n",
            "Class is:  multiple , Index is:  2\n",
            "Class is:  single , Index is:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mYwmUL4hzdN",
        "colab_type": "text"
      },
      "source": [
        "**Next steps**\n",
        "1. Data is already loaded into 2 variables: trainset and validset\n",
        "2. Identify the modules you will need for the classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf-0_BRkhxZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch #Main torch library\n",
        "import torch.nn as nn #Neural Network module, we will build our class\n",
        "import torchvision #Used earlier for data import\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xoeku77jNRo",
        "colab_type": "text"
      },
      "source": [
        "We need to display some sample images. It's best to import with matplotlib. Also import numpy for good measure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzkIvGqqjT-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB5LKYR-jYbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build the image display function\n",
        "#Let's use our previous example as a boiler plate\n",
        "#Lets use the PyTorch built in display method, using the python imaging Library\n",
        "#PIL or Pillow\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "def imshow(img):\n",
        "  img = img/2+0.5 #unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YrdbxjX-tvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig=plt.figure(figsize=(10,10))\n",
        "\n",
        "sub = fig.add_subplot(131)\n",
        "sub = imshow(trainset[500][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UayWD-9r-qv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig=plt.figure(figsize=(10,10))\n",
        "\n",
        "sub = fig.add_subplot(131)\n",
        "sub = imshow(trainset[1200][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ6iJNdU-wdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig=plt.figure(figsize=(10,10))\n",
        "\n",
        "sub = fig.add_subplot(131)\n",
        "sub = imshow(trainset[1300][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvlqSSINlSt1",
        "colab_type": "text"
      },
      "source": [
        "**Define NN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS74H5yilX7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    #in channel\n",
        "    #Two convolution kernels\n",
        "    self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(3380, 50) #Transformation variable\n",
        "    # 921 600\n",
        "    self.fc2 = nn.Linear(50, 4)\n",
        "\n",
        "#Forward method is basically a recursion relationship\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(x.size(0), -1) #Resize\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training) #Inherited from nn.Module\n",
        "    x = F.relu(self.fc2(x))\n",
        "    \n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOTenGIlCha2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c67cfcd6-24ae-44cc-ec65-0100ce366ee7"
      },
      "source": [
        "type(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.Net"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMtSW4OACkPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "12c04b1c-9071-44a6-ba8a-ad99032cd451"
      },
      "source": [
        "print(model) #Print out model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=3380, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=4, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU1CICxzlq23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "033c4dec-2af2-4876-b66d-83f46678b0b8"
      },
      "source": [
        "# Define an optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.05) #Brian used momentum=5\n",
        "optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    lr: 0.001\n",
              "    momentum: 0.05\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcFauyd1laAf",
        "colab_type": "text"
      },
      "source": [
        "To use the NN class we need to define an optimizer.\n",
        "In order to utilize the new neural network class, we need to define an optimizer with torch.optim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NByvZ9SOEfhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epoch, model, data_loader, phase='training', volatile=False):\n",
        "  if phase == 'training':\n",
        "    model.train()\n",
        "  elif phase == 'validation':\n",
        "    model.eval()\n",
        "    volatile=True\n",
        "  running_loss = 0.0\n",
        "  running_correct = 0.0\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(data_loader):\n",
        "    data, target = Variable(data, volatile), Variable(target)\n",
        "  \n",
        "    if phase == 'training':\n",
        "      optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "\n",
        "    running_loss += F.nll_loss(output, target, size_average=False).data\n",
        "    preds = output.data.max(dim=1, keepdim=True)[1] \n",
        "    running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "\n",
        "    if phase == 'training':\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  loss = running_loss / len(data_loader.dataset)\n",
        "  accuracy = 100. * running_correct / len(data_loader.dataset)\n",
        "\n",
        "  print(f'{phase} loss is {loss} and {phase} accuracy is {running_correct} / {len(data_loader.dataset)} = {accuracy}')\n",
        "  return loss, accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTObwYHuDiBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define loss function and accuracy\n",
        "train_losses, train_accuracy = [], []\n",
        "val_losses, val_accuracy = [], []\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(trainset,batch_size=32,num_workers=3,shuffle=True)\n",
        "valid_data_loader = torch.utils.data.DataLoader(validset,batch_size=32,num_workers=3,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dofgCuPSHtcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1,4):\n",
        "  #train model\n",
        "  #validate\n",
        "  #update lists\n",
        "  #Make simple graph of loss function\n",
        "  epoch_loss, epoch_accuracy = fit(epoch, model, train_data_loader, phase='training')\n",
        "  val_epoch_loss, val_epoch_accuracy = fit(epoch, model, valid_data_loader, phase='validation')\n",
        "  train_losses.append(epoch_loss)\n",
        "  train_accuracy.append(epoch_accuracy)\n",
        "  val_losses.append(val_epoch_loss)\n",
        "  val_accuracy.append(val_epoch_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLD547GuQhsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(1, len(train_losses)+1), train_losses, 'bo', label='training loss')\n",
        "plt.plot(range(1, len(val_losses)+1), val_losses, 'r', label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}